MODEL_1

model = Sequential()
    
    model.add(GRU(128, return_sequences=True, input_shape= (n_timesteps,n_features)))
    model.add(Dropout(0.3))
    
    model.add(GRU(64, return_sequences=True))
    model.add(Dropout(0.3))

    model.add(Dense(256, activation='relu'))
    model.add(Flatten())

    model.add(Dense(n_outputs, activation = "softmax"))

    # Define the optimizer
    #optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)
    optimizer = Adam(learning_rate=0.002)

    # Compile the model
    model.compile(optimizer = optimizer , loss = "categorical_crossentropy", metrics=["accuracy"])

    # Model Training
    model_history = model.fit(train_X, train_Y, batch_size = batch_size, epochs = epochs,validation_data = (val_X, val_Y))

    print(model.summary())

________________________________________________________________________________________________________
MODEL_2
	n_timesteps, n_features, n_outputs = train_X.shape[1], train_X.shape[2], train_Y.shape[1]

    model = Sequential()
    
    model.add(Bidirectional(GRU(256, return_sequences=True, input_shape= (n_timesteps,n_features))))
    model.add(Dropout(0.3))
    
    model.add(Bidirectional(GRU(256, return_sequences=True)))
    model.add(Dropout(0.3))

    model.add(Dense(512, activation='relu'))
    model.add(Flatten())

    model.add(Dense(n_outputs, activation = "softmax"))

    # Define the optimizer
    #optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)
    optimizer = Adam(learning_rate=0.002)

    # Compile the model
    model.compile(optimizer = optimizer , loss = "categorical_crossentropy", metrics=["accuracy"])

    # Model Training
    model_history = model.fit(train_X, train_Y, batch_size = batch_size, epochs = epochs,validation_data = (val_X, val_Y))

    print(model.summary())